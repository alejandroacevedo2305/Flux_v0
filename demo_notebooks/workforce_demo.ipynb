{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este cuaderno es una demo del modulo _Simulador_ y el modulo de optizacion (_Workforce_), que usa este para computar una estrategia optima. \n",
    "\n",
    "# Simulador (noviembre 2023)\n",
    "## para simulación: simv06\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/DeepenData/Repos/Flux_v0')\n",
    "from dev.simv06 import simv06, plan_desde_skills\n",
    "from   src.utils_Escritoriosv05_Simv05 import (\n",
    "                                            DatasetTTP,\n",
    "                                            obtener_skills)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset                     = DatasetTTP.desde_csv_atenciones(\"data/fonasa_monjitas.csv.gz\") # IdOficina=2)\n",
    "un_dia                      = dataset.un_dia(\"2023-05-15\").sort_values(by='FH_Emi', inplace=False)\n",
    "skills                      = obtener_skills(un_dia)\n",
    "planificacion               = plan_desde_skills(skills, inicio = '08:00:00')\n",
    "hora_cierre                 = \"16:30:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(registros_atenciones) = 659, len(fila) = 0\n",
      "tiempo total: 4.6 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "registros_atenciones, fila =  simv06(un_dia, hora_cierre, planificacion)\n",
    "print(f\"{len(registros_atenciones) = }, {len(fila) = }\")\n",
    "end_time = time.time()\n",
    "print(f\"tiempo total: {end_time - start_time:.1f} segundos\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "IdOficina : int = 2 # Se le pasa arriba, pero no creo que lo usaba para nada\n",
    "\n",
    "def formatea_tabla_simulador(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df['IdOficina'] = IdOficina\n",
    "    df['FH_AteIni'] = df['FH_Emi'].astype('datetime64[s]') + pd.to_timedelta( df['espera'], unit='seconds' )\n",
    "    df['FH_Llama']  = df['FH_AteIni']  # BUG: posiblemente no necesario\n",
    "    df['FH_AteFin'] = df['FH_AteIni'] + pd.to_timedelta( df['T_Ate'], unit='seconds' )\n",
    "\n",
    "    df = df.rename(columns={'espera' : 'T_Esp'})\n",
    "\n",
    "    return df[[\"IdOficina\",\"IdSerie\",\"IdEsc\",\"FH_Emi\",\"FH_Llama\",\"FH_AteIni\",\"FH_AteFin\",\"T_Esp\",\"T_Ate\"]]\n",
    "\n",
    "\n",
    "# IdOficina\tIdSerie\tIdEsc\tFH_Emi\tFH_Llama\tFH_AteIni\tFH_AteFin\tT_Esp\tT_Ate\n",
    "formatea_tabla_simulador(registros_atenciones).astype({\"IdSerie\":\"category\"}).plot.scatter(x='FH_Emi', y='FH_Llama', c='T_Esp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workforce manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import random\n",
    "import optuna\n",
    "from src.datos_utils import DatasetTTP, obtener_skills\n",
    "from src.optuna_utils import non_empty_subsets\n",
    "import itertools\n",
    "import numpy as np\n",
    "from src.optuna_utils import plan_unico\n",
    "from dev.atributos_de_series import atributos_x_serie\n",
    "import optuna\n",
    "import numpy as np\n",
    "import time\n",
    "from src.optuna_utils import (\n",
    "    sla_x_serie, \n",
    "    extract_skills_length, \n",
    "    non_empty_subsets\n",
    "    )\n",
    "from   src.utils_Escritoriosv05_Simv05 import (\n",
    "                                            get_permutations_array,\n",
    "                                           plan_unico,\n",
    "                                           generar_planificacion,\n",
    "                                           extract_min_value_keys,\n",
    "                                            DatasetTTP,\n",
    "                                            get_time_intervals,\n",
    "                                            partition_dataframe_by_time_intervals)\n",
    "from dev.Escritoriosv05_Simv05 import simv05\n",
    "from dev.atributos_de_series import atributos_x_serie\n",
    "import math\n",
    "\n",
    "def objective(trial, \n",
    "    un_dia : pd.DataFrame,  # IdOficina  IdSerie  IdEsc, FH_Emi, FH_Llama  -- Deberia llamarse 'un_tramo'\n",
    "    subsets: list, # [(5,), (10,), (11,), (12,), (14,), (17,), (5, 10), (5, 11), (5, 12), (5, 14), (5, 17), (10, 11),  <...> 14, 17), (5, 10, 12, 14, 17), (5, 11, 12, 14, 17), (10, 11, 12, 14, 17), (5, 10, 11, 12, 14, 17)]\n",
    "    hora_cierre:str,\n",
    "    modos_atenciones : list = [\"Alternancia\", \"FIFO\", \"Rebalse\"],\n",
    "    pesos_x_serie: dict = None,\n",
    "    optimizar: str = \"SLA\",\n",
    "    minimo_escritorios: int = 2,\n",
    "    maximo_escritorios: int = 5,\n",
    "    niveles_servicio_x_serie = None,\n",
    "    series                   : list = None\n",
    "    ):    \n",
    "    all_permutations = list(itertools.permutations([r+1 for r in range(len(series))]))\n",
    "    try:\n",
    "        \n",
    "        n_escritorios = trial.suggest_int(\n",
    "             f'prioridades', minimo_escritorios, maximo_escritorios )\n",
    "        print(f\"---------------------n_escritorios {n_escritorios}\")\n",
    "        #bool_vector              = [trial.suggest_categorical(f'escritorio_{i}', [True, False]) for i in range(n_escritorios)]\n",
    "        #Restricción de minimo de escritorios\n",
    "        #assert sum(bool_vector) >= minimo_escritorios, f\"No cumple con minimo_escritorios: {minimo_escritorios}.\"\n",
    "        \n",
    "        str_dict                 = {i: trial.suggest_categorical(f'{i}',         modos_atenciones) for i in range(n_escritorios)} \n",
    "        subset_idx               = {i: trial.suggest_int(f'ids_{i}', 0, len(subsets) - 1) for i in range(n_escritorios)}   \n",
    "        #prioridades              =  prioridad_x_serie(niveles_servicio_x_serie, 2, 1) \n",
    "        planificacion_optuna            =  {} # Arma una planificacion con espacios parametricos. \n",
    "        inicio                   =  str(un_dia.FH_Emi.min().time())#'08:33:00'\n",
    "        termino                  =  str(un_dia.FH_Emi.max().time())#'14:33:00'        \n",
    "        #skills_len = len(list(subsets[subset_idx[key]]))        \n",
    "        for key in str_dict.keys():\n",
    "            #if bool_vector[key]:\n",
    "                #skills                    = list(subsets[subset_idx[key]])\n",
    "                #permutaciones_prioridades = get_permutations_array(list(subsets[subset_idx[key]]).__len__())\n",
    "                inner_dict = {\n",
    "                    'inicio': inicio,\n",
    "                    'termino': termino,\n",
    "                    'propiedades': {\n",
    "                        'skills': list(subsets[subset_idx[key]]),# list(subsets[subset_idx[key]]), # Set -> Lista, para el subset 'subset_idx', para el escritorio 'key'\n",
    "                        'configuracion_atencion': str_dict[key], # \n",
    "                        'prioridades': \n",
    "                                    {s: r for s,r in zip(series, all_permutations\n",
    "                                    [trial.suggest_int('idx', 0, len(all_permutations) - 1)])}\n",
    "                                  ,\n",
    "                        'pasos': {i: trial.suggest_int(f'pasos_{i}', 1, 4) for i in list(subsets[subset_idx[key]])},\n",
    "                    }\n",
    "                }\n",
    "                planificacion_optuna[str(key)] = [inner_dict] # NOTE: Es una lista why -- Config por trial por tramo del escritorio \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "        planificacion = {un_escritorio[0]:\n",
    "                [\n",
    "                    {\n",
    "                    'inicio': un_escritorio[1][0]['inicio'],\n",
    "                'termino':un_escritorio[1][0]['termino'],\n",
    "                'propiedades':{\n",
    "                    'skills': un_escritorio[1][0]['propiedades']['skills'],\n",
    "                'configuracion_atencion': un_escritorio[1][0]['propiedades']['configuracion_atencion'],\n",
    "                'porcentaje_actividad'  : np.random.randint(85, 90)/100,                \n",
    "                'atributos_series':\n",
    "                    atributos_x_serie(ids_series=un_escritorio[1][0]['propiedades']['skills'], \n",
    "                                                sla_porcen_user=[niveles_servicio_x_serie[s][0] for s in un_escritorio[1][0]['propiedades']['skills']]\n",
    "            , \n",
    "                                                sla_corte_user=[niveles_servicio_x_serie[s][1] for s in un_escritorio[1][0]['propiedades']['skills']]\n",
    "            , \n",
    "                                                pasos_user=list(un_escritorio[1][0]['propiedades']['pasos'].values()), \n",
    "                                                prioridades_user=list(un_escritorio[1][0]['propiedades']['prioridades'].values())),\n",
    "                },}]\n",
    "                for un_escritorio in planificacion_optuna.items()}\n",
    "\n",
    "                        \n",
    "        trial.set_user_attr('planificacion', planificacion) # This' actually cool \n",
    "        \n",
    "        \n",
    "        nested_list =  [e[0]['propiedades']['skills'] for k, e in  planificacion.items()]\n",
    "        assert set([item for sublist in nested_list for item in sublist]) == set(series), \"no todas las series incluidas\"\n",
    "        \n",
    "        registros_atenciones, _      = simv05(un_dia, hora_cierre, planificacion)   \n",
    "        registros_atenciones['IdSerie'] = registros_atenciones['IdSerie'].astype(int) \n",
    "        registros_x_serie               = [registros_atenciones[registros_atenciones.IdSerie==s] for s in series]\n",
    "        pocentajes_SLA        = [int(100*v[0])for k,v in niveles_servicio_x_serie.items()]\n",
    "        mins_de_corte_SLA     = [int(v[1])for k,v in niveles_servicio_x_serie.items()]        \n",
    "        df_pairs              = [(sla_x_serie(r_x_s, '1H', corte = corte), s) \n",
    "                                 for r_x_s, s, corte in zip(registros_x_serie, series, mins_de_corte_SLA)]\n",
    "        porcentajes_reales    = {f\"serie: {serie}\": np.mean(esperas.espera) for ((demandas, esperas), serie) in df_pairs} \n",
    "        \n",
    "        \n",
    "        assert not any(math.isnan(x) for x in [v for k, v in porcentajes_reales.items()]), \"porcentajes_reales contains at least one nan\"\n",
    "\n",
    "        \n",
    "        print(f\"------------porcentajes_reales {[v for k, v in porcentajes_reales.items()]}\")\n",
    "        print(f\"----------------pocentajes_SLA :{pocentajes_SLA}\")\n",
    "        #print(f\"sla_real: {sla_real} - sla_teorico {sla_teorico}\")\n",
    "        dif_cuadratica        = {k:((sla_real-sla_teorico)**2 if sla_real < sla_teorico else abs((sla_real-sla_teorico)) ) \n",
    "                                 for ((k,sla_real),sla_teorico) in zip(porcentajes_reales.items(),pocentajes_SLA)}\n",
    "        #Objetivos:    \n",
    "        #La mayor prioridad es el entero más chico    \n",
    "        maximizar_SLAs        = tuple(np.array(tuple(pesos_x_serie.values()))*np.array(tuple(dif_cuadratica.values())))#Ponderado por prioridad\n",
    "        minimizar_escritorios = (10*n_escritorios**2,)\n",
    "        minimizar_skills      = (extract_skills_length(planificacion)**2,)\n",
    "        \n",
    "        \n",
    "        \n",
    "        assert not any(math.isnan(x) for x in maximizar_SLAs), \"al menos un SLA NaN\"\n",
    "        \n",
    "        if optimizar == \"SLA\":\n",
    "            \n",
    "            print(f\"--OBJ-- maximizar_SLAs           {maximizar_SLAs}\")\n",
    "            return  maximizar_SLAs\n",
    "        \n",
    "        elif optimizar == \"SLA + escritorios\":\n",
    "            \n",
    "            print(f\"maximizar_SLAs y minimizar_escritorios { maximizar_SLAs + minimizar_escritorios}\")\n",
    "            return  maximizar_SLAs + minimizar_escritorios\n",
    "        \n",
    "        elif optimizar == \"SLA + skills\":\n",
    "            \n",
    "            print(f\"maximizar_SLAs y minimizar_skills {maximizar_SLAs + minimizar_skills}\")\n",
    "            return  maximizar_SLAs + minimizar_skills\n",
    "        \n",
    "        elif optimizar == \"SLA + escritorios + skills\":\n",
    "            \n",
    "            print(f\"SLA + escritorios + skills {maximizar_SLAs + minimizar_escritorios + minimizar_skills}\")\n",
    "            return  maximizar_SLAs + minimizar_escritorios + minimizar_skills        \n",
    "    except Exception as e:\n",
    "        print(f\"An exception occurred: {e}\")\n",
    "        raise optuna.TrialPruned()\n",
    "    \n",
    "dataset                                 = DatasetTTP.desde_csv_atenciones(\"data/fonasa_monjitas.csv.gz\") # IdOficina=2)\n",
    "un_dia                                  = dataset.un_dia(\"2023-05-15\").sort_values(by='FH_Emi', inplace=False)\n",
    "skills       = obtener_skills(un_dia)\n",
    "series       = sorted(list({val for sublist in skills.values() for val in sublist}))\n",
    "atributos_series = atributos_x_serie(ids_series=series, \n",
    "                                    sla_porcen_user=None, \n",
    "                                    sla_corte_user=None, \n",
    "                                    pasos_user=None, \n",
    "                                    prioridades_user=None)\n",
    "niveles_servicio_x_serie = {atr_dict['serie']:\n",
    "                            (atr_dict['sla_porcen']/100, atr_dict['sla_corte']) \n",
    "                            for atr_dict in atributos_series}\n",
    "\n",
    "intervals  = get_time_intervals(un_dia, n = 4, porcentaje_actividad = 1) # Una funcion que recibe un dia, un intervalo, y un porcentaje de actividad para todos los intervalos\n",
    "partitions = partition_dataframe_by_time_intervals(un_dia, intervals) # TODO: implementar como un static del simulador? \n",
    "storage = optuna.storages.get_storage(\"sqlite:///alejandro_objs_v05.db\")\n",
    "n_trials     = 5\n",
    "optimizar    =\"SLA\" #\"SLA + escritorios + skills\" #\"SLA\" | \"SLA + escritorios\" | \"SLA + skills\" | \"SLA + escritorios + skills\"\n",
    "n_objs       = int(\n",
    "                        len(series)\n",
    "                        if optimizar == \"SLA\"\n",
    "                        else len(series) + 1\n",
    "                        if optimizar in {\"SLA + escritorios\", \"SLA + skills\"}\n",
    "                        else len(series) + 2\n",
    "                        if optimizar == \"SLA + escritorios + skills\"\n",
    "                        else None\n",
    "                        )\n",
    "pesos_x_serie = {s: random.randint(1,len(series)) for s in series}\n",
    "for idx, (part, inters) in enumerate(zip(partitions,intervals)):\n",
    "    print(inters)\n",
    "    #print(idx, part, inters[1])\n",
    "    \n",
    "    study_name = f\"tramo_{idx}\"\n",
    "    study = optuna.multi_objective.create_study(directions= n_objs*['minimize'],\n",
    "                                                study_name=study_name,\n",
    "                                                storage=storage, load_if_exists=True)\n",
    "    # TODO: sacar fuera\n",
    "    # Optimize with a timeout (in seconds)\n",
    "    \n",
    "    subsets      = non_empty_subsets(sorted(list({val for sublist in obtener_skills(part).values() for val in sublist})))\n",
    "\n",
    "    \n",
    "    study.optimize(lambda trial: objective(trial,\n",
    "                                           optimizar                = optimizar,\n",
    "                                           un_dia                   = part,\n",
    "                                           subsets                  = subsets,\n",
    "                                           hora_cierre              =  inters[1],\n",
    "                                           pesos_x_serie            = pesos_x_serie,\n",
    "                                           minimo_escritorios       = 10,\n",
    "                                           maximo_escritorios       = 13,\n",
    "                                           niveles_servicio_x_serie = niveles_servicio_x_serie,\n",
    "                                           series                   = sorted(list({val for sublist in obtener_skills(part).values() for val in sublist}))   \n",
    "                                           ),\n",
    "                   n_trials  = n_trials, #int(1e4),  # Make sure this is an integer\n",
    "                   timeout   = 2*3600,   #  hours\n",
    "                   )  # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de la planificación óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendaciones_db   = optuna.storages.get_storage(\"sqlite:///alejandro_objs_v05.db\") # Objetivos de 6-salidas\n",
    "resumenes            = optuna.study.get_all_study_summaries(recomendaciones_db)\n",
    "nombres              = [s.study_name for s in resumenes if \"tramo_\" in s.study_name]\n",
    "\n",
    "scores_studios = {}\n",
    "for un_nombre in nombres:\n",
    "    un_estudio            = optuna.multi_objective.load_study(study_name=un_nombre, storage=recomendaciones_db)\n",
    "    trials_de_un_estudio  = un_estudio.get_trials(deepcopy=False) #or pareto trials??\n",
    "    scores_studios        = scores_studios | {f\"{un_nombre}\":\n",
    "        { trial.number: np.mean([x for x in trial.values if x is not None]) \n",
    "                for\n",
    "                    trial in trials_de_un_estudio if trial.state == optuna.trial.TrialState.COMPLETE}\n",
    "                    } \n",
    "    \n",
    "trials_optimos          = extract_min_value_keys(scores_studios) # Para cada tramo, extrae el maximo, \n",
    "planificaciones_optimas = {}   \n",
    "for k,v in trials_optimos.items():\n",
    "    un_estudio               = optuna.multi_objective.load_study(study_name=k, storage=recomendaciones_db)\n",
    "    trials_de_un_estudio     = un_estudio.get_trials(deepcopy=False)\n",
    "    planificaciones_optimas  = planificaciones_optimas | {f\"{k}\":\n",
    "        trial.user_attrs.get('planificacion')#calcular_optimo(trial.values)\n",
    "                for\n",
    "                    trial in trials_de_un_estudio if trial.number == v[0]\n",
    "                    }   \n",
    "    \n",
    "planificacion_optima   =  plan_unico([plan for tramo,plan in planificaciones_optimas.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulación con planificación óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hora_cierre = \"17:00:00\"\n",
    "registros_atenciones, fila =  simv05(un_dia, hora_cierre, planificacion_optima) \n",
    "print(f\"{len(registros_atenciones) = }, {len(fila) = }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
